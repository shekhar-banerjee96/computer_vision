{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image  = cv2.imread('images.jpeg')\n",
    "cv2.imshow('Armas' , image)\n",
    "cv2.waitKey() # need to write always , asling to wait till another input shown\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 168, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"local_copy_armas.jpeg\",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Black and White"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert color image to Gray - Scale with cvtcolor (convert color)\n",
    "gray_image = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('modi black and white',gray_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 168, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "resequenced_image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('resequenced',resequenced_image)\n",
    "cv2.waitKey()\n",
    "\n",
    "color_img1 = cv2.cvtColor(image, cv2.COLOR_BGR2Luv) \n",
    "cv2.waitKey()\n",
    "\n",
    "color_img2 = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow(\"Color Image\", color_img2)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing image and shapes using OpenCV(CV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = np.zeros((512,512,3))\n",
    "image_bw = np.zeros((512,512,1))\n",
    "\n",
    "cv2.imshow(\"Black Rectangle (Color)\", image)\n",
    "cv2.imshow(\"Black Rectangle (B&W)\", image_bw)\n",
    "\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's draw a line over our black square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((512,512,3))\n",
    "cv2.line(image, (0,0),(400,400), (255,127,0), 5)\n",
    "cv2.imshow(\"Line\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((512,512,3))\n",
    "cv2.rectangle(image, (100,100),(300,400), (255,127,0), -1)\n",
    "cv2.imshow(\"Rectangle\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((512,512,3))\n",
    "cv2.circle(image, (300,300),100, (50,255,10), -1)\n",
    "cv2.imshow(\"circle\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.zeros((512,512,3))\n",
    "cv2.rectangle(image, (100,100),(400,400), (255,127,0), -1)\n",
    "cv2.imshow(\"Rectangle\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2\n",
    "\n",
    "### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Image \n",
    "\n",
    "image = np.zeros((512,512,3))\n",
    "\n",
    "cv2.putText(image ,'Good Morning !',\n",
    "            (75,290),\n",
    "            cv2.FONT_HERSHEY_COMPLEX,\n",
    "            2,(100,170,0),2)\n",
    "\n",
    "cv2.imshow(\"Good Morning\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.warpAffine\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('modi_image.jpeg')\n",
    "# store height and width of the image\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "quarter_height, quarter_width = height/4,width/4\n",
    "quarter_height1, quarter_width1 = height/3,width/3\n",
    "\n",
    "T = np.float32([[1,0,quarter_width],[0,1,quarter_height]])\n",
    "T1 = np.float32([[1,0,quarter_width1],[0,1,quarter_height1]])\n",
    "\n",
    "img_translation = cv2.warpAffine(image, T, (width, height))\n",
    "img_translation1 = cv2.warpAffine(image, T1, (width, height))\n",
    "\n",
    "cv2.imshow(\"Translation\", img_translation)\n",
    "cv2.imshow(\"Translation1\", img_translation1)\n",
    "cv2.imshow(\"original image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image =  cv2.imread('modi_image.jpeg')\n",
    "\n",
    "image_scaled = cv2.resize(image,None, fx = 0.5 , fy = 0.5)\n",
    "cv2.imshow(\"original image\", image)\n",
    "cv2.imshow(\"Sacling - Linear Transformation\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.getRotationMatrix2D\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('modi_image.jpeg')\n",
    "# store height and width of the image\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Divide by two to rotate the image around its centre\n",
    "# cv.getRotationMatrix2D(\tcenter, angle, scale\t) ->\tretval\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2),60, .5)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "\n",
    "cv2.imshow(\"rotation image\", rotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"original image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling, re-sizing and interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('images.jpeg')\n",
    "\n",
    "image_scaled = cv2.resize(image, None,fx = 0.5, fy = 0.5)\n",
    "\n",
    "image_scaled1 = cv2.resize(image, None,fx = 0.5, fy = 0.5, interpolation = cv2.INTER_NEAREST)\n",
    "image_scaled2 = cv2.resize(image, (400,400), interpolation = cv2.INTER_AREA)\n",
    "image_scaled3 = cv2.resize(image, (400,400), interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow(\"INTER_NEAREST\", image_scaled1)\n",
    "cv2.imshow(\"INTER_AREA\", image_scaled2)\n",
    "cv2.imshow(\"INTER_CUBIC\", image_scaled3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pyramids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('modi_image.jpeg')\n",
    "smaller = cv2.pyrDown(image)\n",
    "larger = cv2.pyrUp(image)\n",
    "cv2.imshow(\"original image\", image)\n",
    "cv2.imshow(\"smaller\", smaller)\n",
    "cv2.imshow(\"larger\", larger)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('input.jpg')\n",
    "height, width = image.shape[:2]\n",
    "start_row, start_col = int(height * 0.30 ), int(width * 0.30)\n",
    "end_row, end_col = int(height * 0.9), int(width * 0.9)\n",
    "cropped = image[start_row:end_row, start_col:end_col]\n",
    "cv2.imshow(\"original image\", image)\n",
    "cv2.imshow(\"cropped image\", cropped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('sudoku.PNG')\n",
    "\n",
    "M = np.zeros(image.shape, dtype = 'uint8') + 150\n",
    "\n",
    "added = cv2.add(image, M)\n",
    "subtracted = cv2.subtract(image, M)\n",
    "cv2.imshow(\"original image\", image)\n",
    "cv2.imshow(\"Added image\", added)\n",
    "cv2.imshow(\"subtracted image\", subtracted)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project  - Live Sketch using our webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def sketch(image):\n",
    "    # change color image to gray image\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # blur the image\n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray, (7,5), 0)\n",
    "    # extract edge\n",
    "    canny_edges = cv2.Canny(img_gray_blur,10,70)\n",
    "    # binarize the image\n",
    "    _ , mask = cv2.threshold(canny_edges, 70, 255, cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _ , frame = cap.read()\n",
    "    cv2.imshow('Our Live Sketcher', sketch(frame))\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "# release camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('input.jpg')\n",
    "\n",
    "kernel_sharpening = np.array([[-1,-1,-1],\n",
    "                             [-1,9,-1],\n",
    "                             [-1,-1,-1]])\n",
    "\n",
    "sharpend = cv2.filter2D(image, -1,kernel_sharpening) # convolution \n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.imshow(\"Image Sharpening\", sharpend)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "demo = cv2.imread('input.jpg')\n",
    "image1 = cv2.imread('input.jpg',0) # 0 means grayscale\n",
    "image2 = cv2.imread('input.jpg',1) # 1 means rgb\n",
    "ret, thresh1 = cv2.threshold(image2, 75, 255, cv2.THRESH_BINARY)\n",
    "ret, thresh2 = cv2.threshold(image1, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(image1, 127, 255, cv2.THRESH_TOZERO)\n",
    "ret, thresh4 = cv2.threshold(image1, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "cv2.imshow(\"demo image\", demo)\n",
    "cv2.imshow(\"Original Image1\", image1)\n",
    "cv2.imshow(\"Original Image2\", image2)\n",
    "cv2.imshow(\"1st Threshold image\", thresh1)\n",
    "cv2.imshow(\"2nd Threshold image\", thresh2)\n",
    "cv2.imshow(\"3rd Threshold image\", thresh3)\n",
    "cv2.imshow(\"4th Threshold image\", thresh4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dilation, Erosion, Opening and Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('images.jpeg',0)\n",
    "\n",
    "kernel = np.ones((5,5))\n",
    "\n",
    "# Now we erode\n",
    "erosion = cv2.erode(image, kernel, iterations=1)\n",
    "cv2.imshow(\"Erosion\", erosion)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Dilation\n",
    "dilation = cv2.dilate(image, kernel, iterations=1)\n",
    "cv2.imshow(\"Dilation\", dilation)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Opening - erosion followed by dilation Good for removing noise\n",
    "opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "cv2.imshow('Opening', opening)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Closing - dllation followed by erosion\n",
    "closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow('Closing', closing)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('input.jpg', 0)\n",
    "\n",
    "height, width = image.shape\n",
    "# Extract Sobel Edges\n",
    "\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_or = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "# Laplacian method\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "# Canny Edge Detection - one of the best edge detection *******************************\n",
    "canny = cv2.Canny(image, 50, 120)\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Sobel_x Image\", sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Sobel_y Image\", sobel_y)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Sobel_or\",sobel_or)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"laplacian\",laplacian)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"Canny Edge Detection\", canny)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "image = cv2.imread('modi_image.jpeg', 0)\n",
    "\n",
    "height, width = image.shape\n",
    "\n",
    "# Extract Sobel Edges\n",
    "\n",
    "sobel_x = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "sobel_or = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "\n",
    "# Laplacian method\n",
    "laplacian = cv2.Laplacian(image, cv2.CV_64F)\n",
    "\n",
    "# Canny Edge Detection - one of the best edge detection *******************************\n",
    "canny = cv2.Canny(image, 50, 120)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Original Image\", image)\n",
    "#cv2.imshow(\"Sobel_x Image\", sobel_x)\n",
    "#cv2.imshow(\"Sobel_y Image\", sobel_y)\n",
    "#cv2.imshow(\"Sobel_or\",sobel_or)\n",
    "#cv2.imshow(\"laplacian\",laplacian)\n",
    "cv2.imshow(\"Canny Edge Detection\", canny)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection using HAAR Cascade Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier(\"Haarcascade/haarcascade_frontalface_default.xml\")\n",
    "image = cv2.imread('images/multiple-portraits-of-young-mans-face-EN7YKX.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "if faces is None:\n",
    "    print(\"No Faces Found\")\n",
    "    \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h), (127,0,255),2)\n",
    "    cv2.imshow(\"Face Detection\", image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face and Eye Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 168, 3)\n"
     ]
    }
   ],
   "source": [
    "# combining both face and eye\n",
    "import numpy as np\n",
    "import cv2\n",
    "face_classifier = cv2.CascadeClassifier(\"Haarcascade/haarcascade_frontalface_default.xml\")\n",
    "eye_classifier = cv2.CascadeClassifier(\"Haarcascade/haarcascade_eye.xml\")\n",
    "\n",
    "image = cv2.imread('image.jpg')\n",
    "print(image.shape)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "if faces is None:\n",
    "    print(\"No Faces Found\")\n",
    "    \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w, y+h), (127,0,250), 2)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]    \n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex, ey),(ex+ew, ey+eh),(255,255,0),2)\n",
    "        cv2.imshow(\"Eye Detection\", image)\n",
    "        cv2.waitKey(0)        \n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pedistrian Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "body_classifier = cv2.CascadeClassifier('Haarcascade/haarcascade_fullbody.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('images/walking.avi')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    bodies = body_classifier.detectMultiScale(gray, 1.2, 3)\n",
    "    \n",
    "    for (x,y,w,h) in bodies:\n",
    "        cv2.rectangle(frame, (x,y),(x+w, y+h), (0,255,255),2)\n",
    "        cv2.imshow(\"Pedistrian Detection\", frame)\n",
    "        \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "car_classifier = cv2.CascadeClassifier('Haarcascade/haarcascade_car.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('images/cars.avi')\n",
    "\n",
    "while cap.isOpened():\n",
    "    time.sleep(0.05)\n",
    "    # read frame per second\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cars = car_classifier.detectMultiScale(gray, 1.4,2)\n",
    "    \n",
    "    for (x,y,w,h) in cars:\n",
    "        cv2.rectangle(frame, (x,y),(x+w, y+h), (0,0,255), 2)\n",
    "        cv2.imshow(\"Cars Detection\", frame)\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Colors at one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COLOR_BAYER_BG2BGR',\n",
       " 'COLOR_BAYER_GB2BGR_EA',\n",
       " 'COLOR_BAYER_GR2GRAY',\n",
       " 'COLOR_BAYER_RG2RGBA',\n",
       " 'COLOR_BGR2LAB']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "color_list = [method for method in dir(cv2) if method.startswith('COLOR_') is True]\n",
    "color_list[:100:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n",
      "Error On cv2.COLOR_BAYER_BG2BGR\n",
      "Error On cv2.COLOR_BAYER_BG2BGRA\n",
      "Error On cv2.COLOR_BAYER_BG2BGR_EA\n",
      "Error On cv2.COLOR_BAYER_BG2BGR_VNG\n",
      "Error On cv2.COLOR_BAYER_BG2GRAY\n",
      "Error On cv2.COLOR_BAYER_BG2RGB\n",
      "Error On cv2.COLOR_BAYER_BG2RGBA\n",
      "Error On cv2.COLOR_BAYER_BG2RGB_EA\n",
      "Error On cv2.COLOR_BAYER_BG2RGB_VNG\n",
      "Error On cv2.COLOR_BAYER_BGGR2BGR\n",
      "Error On cv2.COLOR_BAYER_BGGR2BGRA\n",
      "Error On cv2.COLOR_BAYER_BGGR2BGR_EA\n",
      "Error On cv2.COLOR_BAYER_BGGR2BGR_VNG\n",
      "Error On cv2.COLOR_BAYER_BGGR2GRAY\n",
      "Error On cv2.COLOR_BAYER_BGGR2RGB\n",
      "Error On cv2.COLOR_BAYER_BGGR2RGBA\n",
      "Error On cv2.COLOR_BAYER_BGGR2RGB_EA\n",
      "Error On cv2.COLOR_BAYER_BGGR2RGB_VNG\n",
      "Error On cv2.COLOR_BAYER_GB2BGR\n",
      "Error On cv2.COLOR_BAYER_GB2BGRA\n",
      "Error On cv2.COLOR_BAYER_GB2BGR_EA\n",
      "Error On cv2.COLOR_BAYER_GB2BGR_VNG\n",
      "Error On cv2.COLOR_BAYER_GB2GRAY\n",
      "Error On cv2.COLOR_BAYER_GB2RGB\n",
      "Error On cv2.COLOR_BAYER_GB2RGBA\n",
      "Error On cv2.COLOR_BAYER_GB2RGB_EA\n",
      "Error On cv2.COLOR_BAYER_GB2RGB_VNG\n",
      "Error On cv2.COLOR_BAYER_GBRG2BGR\n",
      "Error On cv2.COLOR_BAYER_GBRG2BGRA\n",
      "Error On cv2.COLOR_BAYER_GBRG2BGR_EA\n",
      "Error On cv2.COLOR_BAYER_GBRG2BGR_VNG\n",
      "Error On cv2.COLOR_BAYER_GBRG2GRAY\n",
      "Error On cv2.COLOR_BAYER_GBRG2RGB\n",
      "Error On cv2.COLOR_BAYER_GBRG2RGBA\n",
      "Error On cv2.COLOR_BAYER_GBRG2RGB_EA\n",
      "Error On cv2.COLOR_BAYER_GBRG2RGB_VNG\n",
      "Error On cv2.COLOR_BAYER_GR2BGR\n",
      "Error On cv2.COLOR_BAYER_GR2BGRA\n",
      "Error On cv2.COLOR_BAYER_GR2BGR_EA\n",
      "Error On cv2.COLOR_BAYER_GR2BGR_VNG\n",
      "Error On cv2.COLOR_BAYER_GR2GRAY\n",
      "Error On cv2.COLOR_BAYER_GR2RGB\n",
      "Error On cv2.COLOR_BAYER_GR2RGBA\n",
      "Error On cv2.COLOR_BAYER_GR2RGB_EA\n",
      "Error On cv2.COLOR_BAYER_GR2RGB_VNG\n",
      "Error On cv2.COLOR_BAYER_GRBG2BGR\n",
      "Error On cv2.COLOR_BAYER_GRBG2BGRA\n",
      "Error On cv2.COLOR_BAYER_GRBG2BGR_EA\n",
      "Error On cv2.COLOR_BAYER_GRBG2BGR_VNG\n",
      "Error On cv2.COLOR_BAYER_GRBG2GRAY\n",
      "Error On cv2.COLOR_BAYER_GRBG2RGB\n",
      "Error On cv2.COLOR_BAYER_GRBG2RGBA\n",
      "Error On cv2.COLOR_BAYER_GRBG2RGB_EA\n",
      "Error On cv2.COLOR_BAYER_GRBG2RGB_VNG\n",
      "Error On cv2.COLOR_BAYER_RG2BGR\n",
      "Error On cv2.COLOR_BAYER_RG2BGRA\n",
      "Error On cv2.COLOR_BAYER_RG2BGR_EA\n",
      "Error On cv2.COLOR_BAYER_RG2BGR_VNG\n",
      "Error On cv2.COLOR_BAYER_RG2GRAY\n",
      "Error On cv2.COLOR_BAYER_RG2RGB\n",
      "Error On cv2.COLOR_BAYER_RG2RGBA\n",
      "Error On cv2.COLOR_BAYER_RG2RGB_EA\n",
      "Error On cv2.COLOR_BAYER_RG2RGB_VNG\n",
      "Error On cv2.COLOR_BAYER_RGGB2BGR\n",
      "Error On cv2.COLOR_BAYER_RGGB2BGRA\n",
      "Error On cv2.COLOR_BAYER_RGGB2BGR_EA\n",
      "Error On cv2.COLOR_BAYER_RGGB2BGR_VNG\n",
      "Error On cv2.COLOR_BAYER_RGGB2GRAY\n",
      "Error On cv2.COLOR_BAYER_RGGB2RGB\n",
      "Error On cv2.COLOR_BAYER_RGGB2RGBA\n",
      "Error On cv2.COLOR_BAYER_RGGB2RGB_EA\n",
      "Error On cv2.COLOR_BAYER_RGGB2RGB_VNG\n",
      "Error On cv2.COLOR_BGR2BGR555\n",
      "Error On cv2.COLOR_BGR2BGR565\n",
      "Error On cv2.COLOR_BGR5552BGR\n",
      "Error On cv2.COLOR_BGR5552BGRA\n",
      "Error On cv2.COLOR_BGR5552GRAY\n",
      "Error On cv2.COLOR_BGR5552RGB\n",
      "Error On cv2.COLOR_BGR5552RGBA\n",
      "Error On cv2.COLOR_BGR5652BGR\n",
      "Error On cv2.COLOR_BGR5652BGRA\n",
      "Error On cv2.COLOR_BGR5652GRAY\n",
      "Error On cv2.COLOR_BGR5652RGB\n",
      "Error On cv2.COLOR_BGR5652RGBA\n",
      "Error On cv2.COLOR_BGRA2BGR555\n",
      "Error On cv2.COLOR_BGRA2BGR565\n",
      "Error On cv2.COLOR_BayerBG2BGR\n",
      "Error On cv2.COLOR_BayerBG2BGRA\n",
      "Error On cv2.COLOR_BayerBG2BGR_EA\n",
      "Error On cv2.COLOR_BayerBG2BGR_VNG\n",
      "Error On cv2.COLOR_BayerBG2GRAY\n",
      "Error On cv2.COLOR_BayerBG2RGB\n",
      "Error On cv2.COLOR_BayerBG2RGBA\n",
      "Error On cv2.COLOR_BayerBG2RGB_EA\n",
      "Error On cv2.COLOR_BayerBG2RGB_VNG\n",
      "Error On cv2.COLOR_BayerBGGR2BGR\n",
      "Error On cv2.COLOR_BayerBGGR2BGRA\n",
      "Error On cv2.COLOR_BayerBGGR2BGR_EA\n",
      "Error On cv2.COLOR_BayerBGGR2BGR_VNG\n",
      "Error On cv2.COLOR_BayerBGGR2GRAY\n",
      "Error On cv2.COLOR_BayerBGGR2RGB\n",
      "Error On cv2.COLOR_BayerBGGR2RGBA\n",
      "Error On cv2.COLOR_BayerBGGR2RGB_EA\n",
      "Error On cv2.COLOR_BayerBGGR2RGB_VNG\n",
      "Error On cv2.COLOR_BayerGB2BGR\n",
      "Error On cv2.COLOR_BayerGB2BGRA\n",
      "Error On cv2.COLOR_BayerGB2BGR_EA\n",
      "Error On cv2.COLOR_BayerGB2BGR_VNG\n",
      "Error On cv2.COLOR_BayerGB2GRAY\n",
      "Error On cv2.COLOR_BayerGB2RGB\n",
      "Error On cv2.COLOR_BayerGB2RGBA\n",
      "Error On cv2.COLOR_BayerGB2RGB_EA\n",
      "Error On cv2.COLOR_BayerGB2RGB_VNG\n",
      "Error On cv2.COLOR_BayerGBRG2BGR\n",
      "Error On cv2.COLOR_BayerGBRG2BGRA\n",
      "Error On cv2.COLOR_BayerGBRG2BGR_EA\n",
      "Error On cv2.COLOR_BayerGBRG2BGR_VNG\n",
      "Error On cv2.COLOR_BayerGBRG2GRAY\n",
      "Error On cv2.COLOR_BayerGBRG2RGB\n",
      "Error On cv2.COLOR_BayerGBRG2RGBA\n",
      "Error On cv2.COLOR_BayerGBRG2RGB_EA\n",
      "Error On cv2.COLOR_BayerGBRG2RGB_VNG\n",
      "Error On cv2.COLOR_BayerGR2BGR\n",
      "Error On cv2.COLOR_BayerGR2BGRA\n",
      "Error On cv2.COLOR_BayerGR2BGR_EA\n",
      "Error On cv2.COLOR_BayerGR2BGR_VNG\n",
      "Error On cv2.COLOR_BayerGR2GRAY\n",
      "Error On cv2.COLOR_BayerGR2RGB\n",
      "Error On cv2.COLOR_BayerGR2RGBA\n",
      "Error On cv2.COLOR_BayerGR2RGB_EA\n",
      "Error On cv2.COLOR_BayerGR2RGB_VNG\n",
      "Error On cv2.COLOR_BayerGRBG2BGR\n",
      "Error On cv2.COLOR_BayerGRBG2BGRA\n",
      "Error On cv2.COLOR_BayerGRBG2BGR_EA\n",
      "Error On cv2.COLOR_BayerGRBG2BGR_VNG\n",
      "Error On cv2.COLOR_BayerGRBG2GRAY\n",
      "Error On cv2.COLOR_BayerGRBG2RGB\n",
      "Error On cv2.COLOR_BayerGRBG2RGBA\n",
      "Error On cv2.COLOR_BayerGRBG2RGB_EA\n",
      "Error On cv2.COLOR_BayerGRBG2RGB_VNG\n",
      "Error On cv2.COLOR_BayerRG2BGR\n",
      "Error On cv2.COLOR_BayerRG2BGRA\n",
      "Error On cv2.COLOR_BayerRG2BGR_EA\n",
      "Error On cv2.COLOR_BayerRG2BGR_VNG\n",
      "Error On cv2.COLOR_BayerRG2GRAY\n",
      "Error On cv2.COLOR_BayerRG2RGB\n",
      "Error On cv2.COLOR_BayerRG2RGBA\n",
      "Error On cv2.COLOR_BayerRG2RGB_EA\n",
      "Error On cv2.COLOR_BayerRG2RGB_VNG\n",
      "Error On cv2.COLOR_BayerRGGB2BGR\n",
      "Error On cv2.COLOR_BayerRGGB2BGRA\n",
      "Error On cv2.COLOR_BayerRGGB2BGR_EA\n",
      "Error On cv2.COLOR_BayerRGGB2BGR_VNG\n",
      "Error On cv2.COLOR_BayerRGGB2GRAY\n",
      "Error On cv2.COLOR_BayerRGGB2RGB\n",
      "Error On cv2.COLOR_BayerRGGB2RGBA\n",
      "Error On cv2.COLOR_BayerRGGB2RGB_EA\n",
      "Error On cv2.COLOR_BayerRGGB2RGB_VNG\n",
      "Error On cv2.COLOR_COLORCVT_MAX\n",
      "Error On cv2.COLOR_GRAY2BGR\n",
      "Error On cv2.COLOR_GRAY2BGR555\n",
      "Error On cv2.COLOR_GRAY2BGR565\n",
      "Error On cv2.COLOR_GRAY2BGRA\n",
      "Error On cv2.COLOR_GRAY2RGB\n",
      "Error On cv2.COLOR_GRAY2RGBA\n",
      "Error On cv2.COLOR_M_RGBA2RGBA\n",
      "Error On cv2.COLOR_RGB2BGR555\n",
      "Error On cv2.COLOR_RGB2BGR565\n",
      "Error On cv2.COLOR_RGBA2BGR555\n",
      "Error On cv2.COLOR_RGBA2BGR565\n",
      "Error On cv2.COLOR_RGBA2M_RGBA\n",
      "Error On cv2.COLOR_RGBA2mRGBA\n",
      "Error On cv2.COLOR_YUV2BGRA_I420\n",
      "Error On cv2.COLOR_YUV2BGRA_IYUV\n",
      "Error On cv2.COLOR_YUV2BGRA_NV12\n",
      "Error On cv2.COLOR_YUV2BGRA_NV21\n",
      "Error On cv2.COLOR_YUV2BGRA_UYNV\n",
      "Error On cv2.COLOR_YUV2BGRA_UYVY\n",
      "Error On cv2.COLOR_YUV2BGRA_Y422\n",
      "Error On cv2.COLOR_YUV2BGRA_YUNV\n",
      "Error On cv2.COLOR_YUV2BGRA_YUY2\n",
      "Error On cv2.COLOR_YUV2BGRA_YUYV\n",
      "Error On cv2.COLOR_YUV2BGRA_YV12\n",
      "Error On cv2.COLOR_YUV2BGRA_YVYU\n",
      "Error On cv2.COLOR_YUV2BGR_I420\n",
      "Error On cv2.COLOR_YUV2BGR_IYUV\n",
      "Error On cv2.COLOR_YUV2BGR_NV12\n",
      "Error On cv2.COLOR_YUV2BGR_NV21\n",
      "Error On cv2.COLOR_YUV2BGR_UYNV\n",
      "Error On cv2.COLOR_YUV2BGR_UYVY\n",
      "Error On cv2.COLOR_YUV2BGR_Y422\n",
      "Error On cv2.COLOR_YUV2BGR_YUNV\n",
      "Error On cv2.COLOR_YUV2BGR_YUY2\n",
      "Error On cv2.COLOR_YUV2BGR_YUYV\n",
      "Error On cv2.COLOR_YUV2BGR_YV12\n",
      "Error On cv2.COLOR_YUV2BGR_YVYU\n",
      "Error On cv2.COLOR_YUV2GRAY_420\n",
      "Error On cv2.COLOR_YUV2GRAY_I420\n",
      "Error On cv2.COLOR_YUV2GRAY_IYUV\n",
      "Error On cv2.COLOR_YUV2GRAY_NV12\n",
      "Error On cv2.COLOR_YUV2GRAY_NV21\n",
      "Error On cv2.COLOR_YUV2GRAY_UYNV\n",
      "Error On cv2.COLOR_YUV2GRAY_UYVY\n",
      "Error On cv2.COLOR_YUV2GRAY_Y422\n",
      "Error On cv2.COLOR_YUV2GRAY_YUNV\n",
      "Error On cv2.COLOR_YUV2GRAY_YUY2\n",
      "Error On cv2.COLOR_YUV2GRAY_YUYV\n",
      "Error On cv2.COLOR_YUV2GRAY_YV12\n",
      "Error On cv2.COLOR_YUV2GRAY_YVYU\n",
      "Error On cv2.COLOR_YUV2RGBA_I420\n",
      "Error On cv2.COLOR_YUV2RGBA_IYUV\n",
      "Error On cv2.COLOR_YUV2RGBA_NV12\n",
      "Error On cv2.COLOR_YUV2RGBA_NV21\n",
      "Error On cv2.COLOR_YUV2RGBA_UYNV\n",
      "Error On cv2.COLOR_YUV2RGBA_UYVY\n",
      "Error On cv2.COLOR_YUV2RGBA_Y422\n",
      "Error On cv2.COLOR_YUV2RGBA_YUNV\n",
      "Error On cv2.COLOR_YUV2RGBA_YUY2\n",
      "Error On cv2.COLOR_YUV2RGBA_YUYV\n",
      "Error On cv2.COLOR_YUV2RGBA_YV12\n",
      "Error On cv2.COLOR_YUV2RGBA_YVYU\n",
      "Error On cv2.COLOR_YUV2RGB_I420\n",
      "Error On cv2.COLOR_YUV2RGB_IYUV\n",
      "Error On cv2.COLOR_YUV2RGB_NV12\n",
      "Error On cv2.COLOR_YUV2RGB_NV21\n",
      "Error On cv2.COLOR_YUV2RGB_UYNV\n",
      "Error On cv2.COLOR_YUV2RGB_UYVY\n",
      "Error On cv2.COLOR_YUV2RGB_Y422\n",
      "Error On cv2.COLOR_YUV2RGB_YUNV\n",
      "Error On cv2.COLOR_YUV2RGB_YUY2\n",
      "Error On cv2.COLOR_YUV2RGB_YUYV\n",
      "Error On cv2.COLOR_YUV2RGB_YV12\n",
      "Error On cv2.COLOR_YUV2RGB_YVYU\n",
      "Error On cv2.COLOR_YUV420P2BGR\n",
      "Error On cv2.COLOR_YUV420P2BGRA\n",
      "Error On cv2.COLOR_YUV420P2GRAY\n",
      "Error On cv2.COLOR_YUV420P2RGB\n",
      "Error On cv2.COLOR_YUV420P2RGBA\n",
      "Error On cv2.COLOR_YUV420SP2BGR\n",
      "Error On cv2.COLOR_YUV420SP2BGRA\n",
      "Error On cv2.COLOR_YUV420SP2GRAY\n",
      "Error On cv2.COLOR_YUV420SP2RGB\n",
      "Error On cv2.COLOR_YUV420SP2RGBA\n",
      "Error On cv2.COLOR_YUV420p2BGR\n",
      "Error On cv2.COLOR_YUV420p2BGRA\n",
      "Error On cv2.COLOR_YUV420p2GRAY\n",
      "Error On cv2.COLOR_YUV420p2RGB\n",
      "Error On cv2.COLOR_YUV420p2RGBA\n",
      "Error On cv2.COLOR_YUV420sp2BGR\n",
      "Error On cv2.COLOR_YUV420sp2BGRA\n",
      "Error On cv2.COLOR_YUV420sp2GRAY\n",
      "Error On cv2.COLOR_YUV420sp2RGB\n",
      "Error On cv2.COLOR_YUV420sp2RGBA\n",
      "Error On cv2.COLOR_mRGBA2RGBA\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('rdj.jpg')\n",
    "color_list = [method for method in dir(cv2) if method.startswith('COLOR_') is True]\n",
    "print(len(color_list))\n",
    "for color in range(len(color_list)):\n",
    "    col_name = color_list[color]\n",
    "    col_code = \"cv2.\"+col_name\n",
    "    resized = cv2.resize(image, (400,400))\n",
    "    try:\n",
    "        rgb_image = cv2.cvtColor(resized, eval(col_code))\n",
    "        cv2.imshow(col_name +\"_\" + str(color), rgb_image)\n",
    "        cv2.waitKey()\n",
    "    except Exception as e:\n",
    "        print(\"Error On\", str(col_code))\n",
    "        pass\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyAutoGUI\n",
    "import pyautogui\n",
    "image = pyautogui.screenshot()\n",
    "image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite('capture_screenshot.png', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing running object with boundary box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "video = cv2.VideoCapture('images/road_car_view.mp4')\n",
    "while True:\n",
    "    ret, or_frame = video.read()\n",
    "    if not ret:\n",
    "        video = cv2.VideoCapture('images/road_car_view.mp4')\n",
    "        continue\n",
    "    frame = cv2.GaussianBlur(or_frame, (5,5), 0)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    lower_y = np.array([18,94,140])\n",
    "    upper_y = np.array([48,255,255])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_y, upper_y)\n",
    "    edges = cv2.Canny(mask, 74,150)\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, maxLineGap=50)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1,y1,x2,y2 = line[0]\n",
    "            cv2.line(frame, (x1,y1),(x2, y2),(0,255,0), 5)\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"edge\", edges)\n",
    "    key = cv2.waitKey(25)\n",
    "    if (key==27):\n",
    "        break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video.mp4\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Enable web camera\n",
    "cap = cv2.VideoCapture(\"images/video.mp4\")\n",
    "\n",
    "# Algorithm\n",
    "#algo = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "algo1 = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read() # FPS\n",
    "    gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3),5)\n",
    "    \n",
    "    # Applying on each frame\n",
    "    img_sub = algo1.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5,5)))\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel)\n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "    counterShape = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.imshow(\"Original Video\", dilatada)\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Time Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car is detected :1\n",
      "Car is detected :2\n",
      "Car is detected :3\n",
      "Car is detected :4\n",
      "Car is detected :5\n",
      "Car is detected :6\n",
      "Car is detected :7\n",
      "Car is detected :8\n",
      "Car is detected :9\n"
     ]
    }
   ],
   "source": [
    "#video.mp4\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "min_width_rect = 80\n",
    "min_height_rect = 80\n",
    "\n",
    "offset = 6 #allow error between pixel\n",
    "delay = 60 # FPS do video\n",
    "carros = 0\n",
    "count_line_pos = 550\n",
    "detec = []\n",
    "def central_handle(x,y,w,h): # function to calculate coordinates of the \n",
    "    x1 = int(w/2)\n",
    "    y1 = int(h/2)\n",
    "    cx = x + x1\n",
    "    cy = y + y1\n",
    "    return cx, cy\n",
    "# Enable web camera\n",
    "cap = cv2.VideoCapture(\"images/video.mp4\")\n",
    "# Algorithm\n",
    "#algo = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "algo1 = cv2.createBackgroundSubtractorMOG2()\n",
    "while True:\n",
    "    ret, frame1 = cap.read() # FPS\n",
    "    gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3),5)    \n",
    "    # Applying on each frame\n",
    "    img_sub = algo1.apply(blur)\n",
    "    dilat = cv2.dilate(img_sub, np.ones((5,5))) # Reduce noise\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5)) # create kernel \n",
    "    dilatada = cv2.morphologyEx(dilat, cv2.MORPH_CLOSE, kernel) \n",
    "    dilatada = cv2.morphologyEx(dilatada, cv2.MORPH_CLOSE, kernel)\n",
    "    counterShape, h = cv2.findContours(dilatada, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)    # find contours\n",
    "\n",
    "    cv2.line(frame1, (25,count_line_pos), (1200, count_line_pos), (0,0,255),3)    # creating the red reference line\n",
    "\n",
    "    for (i,c) in enumerate(counterShape):\n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        validar_contorno = (w >= min_width_rect) and (h >= min_height_rect)       # Checking of they have the minimum size\n",
    "\n",
    "        if not validar_contorno: # keep of running if no countors found.\n",
    "            continue\n",
    "\n",
    "        \"\"\"Before the red reference line\"\"\"\n",
    "        # create bounding box\n",
    "        cv2.rectangle(frame1, (x,y), (x+w, y+h), (255,0,0),2)\n",
    "\n",
    "        # put label text\n",
    "        cv2.putText(frame1, \"vehicle\" + str(carros), (x,y-20), cv2.FONT_HERSHEY_TRIPLEX, 1,(0,255,100),2)\n",
    "        # compute the center of the vehicle image\n",
    "        center = central_handle(x,y,w,h)\n",
    "        detec.append(center)        \n",
    "        cv2.circle(frame1, center, 4, (100,255,200),-1)        \n",
    "        # Loop Function  to check if the red reference line       \n",
    "        for (x, y) in detec:\n",
    "            \"\"\" After the red reference line \"\"\"\n",
    "            if y <(count_line_pos + offset) and y > (count_line_pos - offset):\n",
    "                # check position of they are at the red reference line or not.\n",
    "                carros +=1\n",
    "                # increment the counter if they pass , add \n",
    "                cv2.line(frame1, (25, count_line_pos),(1200, count_line_pos),(50,50,255),3)\n",
    "                detec.remove((x,y))\n",
    "                print(\"Car is detected :\" + str(carros))   \n",
    "    # Total Counter             \n",
    "    cv2.putText(frame1, \"Vehicle count :\" + str(carros), (450,70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,255),5)\n",
    "    cv2.imshow(\"Original Video\", frame1)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
